import gradio as gr
import pandas as pd
import datetime
from nasa_api import obtener_datos_meteorologicos, PROVINCIAS_COORDS
from forecast_model import predecir_precipitacion
from utils import (
    graficar_historico, graficar_prediccion, 
    graficar_temperatura, graficar_comparativo_anual,
    calcular_estadisticas_climaticas, generar_reporte_climatico
)
from mcp_core import MCPContext, QdrantRetriever
from agents import AdvisorAgent

def _generar_opciones_fechas():
    """Genera lista de opciones de fechas desde 1981-01 hasta el mes actual."""
    opciones = []
    fecha_actual = datetime.date.today()
    
    for a√±o in range(1981, fecha_actual.year + 1):
        mes_fin = 12 if a√±o < fecha_actual.year else fecha_actual.month
        for mes in range(1, mes_fin + 1):
            opciones.append(f"{a√±o}-{mes:02d}")
    
    return opciones

def _obtener_fecha_actual():
    """Obtiene la fecha actual en formato YYYY-MM."""
    fecha_actual = datetime.date.today()
    return f"{fecha_actual.year}-{fecha_actual.month:02d}"

def analizar_provincia_completo(provincia, incluir_temperatura=True, incluir_comparativo=True, fecha_inicio=None, fecha_fin=None, progress=gr.Progress()):
    """An√°lisis meteorol√≥gico completo de una provincia con indicador de progreso."""
    try:
        progress(0.1, desc="Iniciando an√°lisis...")
        
        # Obtener datos meteorol√≥gicos completos
        progress(0.2, desc="Obteniendo datos de NASA POWER...")
        df_completo = obtener_datos_meteorologicos(provincia, fecha_inicio, fecha_fin)
        
        progress(0.4, desc="Procesando datos clim√°ticos...")
        df_precipitacion = df_completo[['ds', 'y']]
        
        # Generar predicci√≥n
        progress(0.5, desc="Generando predicciones con IA...")
        forecast = predecir_precipitacion(df_precipitacion)
        
        # Calcular estad√≠sticas clim√°ticas
        progress(0.6, desc="Calculando estad√≠sticas...")
        estadisticas = calcular_estadisticas_climaticas(df_completo)
        
        # Generar reporte detallado
        progress(0.7, desc="Generando reporte detallado...")
        reporte = generar_reporte_climatico(provincia, df_completo, forecast, estadisticas, fecha_inicio, fecha_fin)
        
        # Generar gr√°ficos
        progress(0.8, desc="Creando visualizaciones...")
        graficos = []
        
        # Gr√°fico de precipitaci√≥n hist√≥rica (siempre incluido)
        graficos.append(graficar_historico(df_precipitacion, provincia))
        
        # Gr√°fico de predicci√≥n (siempre incluido)
        graficos.append(graficar_prediccion(forecast, provincia))
        
        # Gr√°fico de temperatura (opcional)
        if incluir_temperatura and 'temperatura' in df_completo.columns:
            graficos.append(graficar_temperatura(df_completo, provincia))
        else:
            graficos.append(None)
        
        # Gr√°fico comparativo anual (opcional)
        if incluir_comparativo:
            graficos.append(graficar_comparativo_anual(df_completo, provincia))
        else:
            graficos.append(None)
        
        progress(1.0, desc="¬°An√°lisis completado!")
        # Devolvemos el reporte dos veces: para el Textbox y para el gr.State que usa el chat
        return reporte, *graficos, reporte
        
    except Exception as e:
        mensaje = f"‚ùå Error al procesar datos de {provincia}: {str(e)}"
        return mensaje, None, None, None, None, ""

def crear_ui():
    """Crea la interfaz de usuario mejorada y funcional."""
    
    # Cargar CSS desde archivo externo
    try:
        with open('styles.css', 'r', encoding='utf-8') as f:
            custom_css = f.read()
    except FileNotFoundError:
        # CSS de respaldo en caso de que no se encuentre el archivo
        custom_css = ""
    
    # Lista de provincias ordenada
    provincias_lista = sorted(list(PROVINCIAS_COORDS.keys()))
    
    # Interfaz mejorada
    with gr.Blocks(css=custom_css, title="Lluv.IA", theme=gr.themes.Soft()) as app:
        
        with gr.Column(elem_classes=["main-container"]):
            # Header profesional
            with gr.Column(elem_classes=["header-container"]):
                gr.HTML('<h1 class="main-title">Lluv.IA</h1>')
                gr.HTML('<p class="main-subtitle">Predicci√≥n y an√°lisis clim√°tico para todas las provincias argentinas</p>')
            
            with gr.Row():
                with gr.Column(scale=3):
                    # Controles principales
                    provincia_input = gr.Dropdown(
                        choices=provincias_lista,
                        value="Buenos Aires",
                        label="üó∫Ô∏è Seleccionar Provincia",
                        info="Eleg√≠ una provincia para analizar"
                    )
                    
                    # Selector de rango de fechas
                    with gr.Row():
                        fecha_inicio_input = gr.Dropdown(
                            choices=_generar_opciones_fechas(),
                            value="1981-01",
                            label="üìÖ Fecha de Inicio",
                            info="A√±o y mes de inicio del an√°lisis"
                        )
                        fecha_fin_input = gr.Dropdown(
                            choices=_generar_opciones_fechas(),
                            value=_obtener_fecha_actual(),
                            label="üìÖ Fecha de Fin",
                            info="A√±o y mes de fin del an√°lisis"
                        )
                    
                    with gr.Row():
                        incluir_temp = gr.Checkbox(
                            value=True,
                            label="üå°Ô∏è Incluir an√°lisis de temperatura"
                        )
                        incluir_comp = gr.Checkbox(
                            value=True,
                            label="üìä Incluir comparativo anual"
                        )
                    
                    analizar_btn = gr.Button(
                        "üîç Analizar Clima",
                        variant="primary",
                        size="lg"
                    )
                
                with gr.Column(scale=1, elem_classes=["info-panel"]):
                    gr.HTML("""
                        <h3>üìã Informaci√≥n</h3>
                        
                        <div style="margin-bottom: 1rem;">
                            <div style="color: #ffffff; font-weight: 600; margin-bottom: 0.25rem;">
                                üåßÔ∏è <strong>Precipitaciones</strong>
                            </div>
                            <div style="color: #f1f5f9; font-size: 0.9rem;">
                                Datos hist√≥ricos 1981-2025
                            </div>
                        </div>
                        
                        <div style="margin-bottom: 1rem;">
                            <div style="color: #ffffff; font-weight: 600; margin-bottom: 0.25rem;">
                                üå°Ô∏è <strong>Temperatura</strong>
                            </div>
                            <div style="color: #f1f5f9; font-size: 0.9rem;">
                                Promedio, m√°xima y m√≠nima
                            </div>
                        </div>
                        
                        <div style="margin-bottom: 1rem;">
                            <div style="color: #ffffff; font-weight: 600; margin-bottom: 0.25rem;">
                                üíß <strong>Humedad</strong>
                            </div>
                            <div style="color: #f1f5f9; font-size: 0.9rem;">
                                Humedad relativa del aire
                            </div>
                        </div>
                        
                        <div style="margin-bottom: 1rem;">
                            <div style="color: #ffffff; font-weight: 600; margin-bottom: 0.25rem;">
                                üîÆ <strong>Predicci√≥n</strong>
                            </div>
                            <div style="color: #f1f5f9; font-size: 0.9rem;">
                                Proyecci√≥n a 24 meses
                            </div>
                        </div>
                        
                        <div>
                            <div style="color: #ffffff; font-weight: 600; margin-bottom: 0.25rem;">
                                üìä <strong>M√©tricas</strong>
                            </div>
                            <div style="color: #f1f5f9; font-size: 0.9rem;">
                                ‚Ä¢ Promedios hist√≥ricos<br>
                                ‚Ä¢ Tendencias estacionales<br>
                                ‚Ä¢ √çndices de variabilidad<br>
                                ‚Ä¢ Alertas clim√°ticas
                            </div>
                        </div>
                    """)
            
            # Resultados
            reporte_output = gr.Textbox(
                label="üìà Reporte Clim√°tico Detallado",
                lines=12,
                show_copy_button=True,
                placeholder="Seleccion√° una provincia y hac√© clic en 'Analizar Clima' para ver el reporte completo..."
            )
            
            # Gr√°ficos en pesta√±as
            with gr.Tabs():
                with gr.TabItem("üåßÔ∏è Precipitaciones Hist√≥ricas"):
                    plot_historico = gr.Plot()
                
                with gr.TabItem("üîÆ Predicci√≥n Futura"):
                    plot_prediccion = gr.Plot()
                
                with gr.TabItem("üå°Ô∏è An√°lisis de Temperatura"):
                    plot_temperatura = gr.Plot()
                
                with gr.TabItem("üìä Comparativo Anual"):
                    plot_comparativo = gr.Plot()
                
                with gr.TabItem("ü§ñ Recomendador de riego"):
                    chat = gr.Chatbot(label="Recomendador de riego", height=400, type='messages')
                    with gr.Row():
                        user_msg = gr.Textbox(placeholder="Pregunt√°: '¬øC√≥mo viene la tendencia de lluvias en C√≥rdoba?'", label="Mensaje", scale=4)
                        send_btn = gr.Button("Enviar", variant="primary", scale=1)
                    backend_label = gr.HTML(value='<div class="backend-label">Modelo: (detectando)</div>')
                    # Estados MCP
                    mcp_state = gr.State(value=None)
                    advisor_state = gr.State(value=None)
                    reporte_state = gr.State(value=None)
                    qdrant_state = gr.State(value=None)
                    
                    def _chat_respond(message, history, mcp, advisor, reporte_txt, qdrant_retriever):
                        if mcp is None or advisor is None:
                            mcp = MCPContext()
                            advisor = AdvisorAgent(mcp, model="google/flan-t5-base")
                        
                        # Inicializar Qdrant solo si OpenAI est√° activo
                        if qdrant_retriever is None and advisor.llm.is_openai_active():
                            qdrant_retriever = QdrantRetriever()
                            if qdrant_retriever.is_available():
                                print("‚úÖ Qdrant conectado y disponible para b√∫squeda vectorial")
                            else:
                                print("‚ö†Ô∏è Qdrant no disponible (verifica QDRANT_URL y QDRANT_API_KEY)")
                                qdrant_retriever = None
                        # Normalizar historial al formato messages [{role, content}]
                        history = history or []
                        if history and isinstance(history[0], (list, tuple)):
                            try:
                                history = (
                                    [{"role": "user", "content": u} , {"role": "assistant", "content": a}]
                                    for (u, a) in history
                                )
                            except Exception:
                                history = []
                            # Aplanar pares en una sola lista
                            flat = []
                            for pair in history:
                                flat.extend(pair)
                            history = flat
                        if not message:
                            # Actualizar backend label aun sin mensaje
                            try:
                                bk = advisor.llm.backend()
                                mcp.set("llm_backend", bk)
                            except Exception:
                                bk = "(desconocido)"
                            return history, mcp, advisor, reporte_txt, qdrant_retriever, f'<div class="backend-label">Modelo: {bk}</div>'
                        
                        # Buscar contexto en Qdrant solo si OpenAI est√° activo
                        qdrant_context = ""
                        if qdrant_retriever is not None and qdrant_retriever.is_available():
                            try:
                                qdrant_context = qdrant_retriever.get_context(message, limit=3)
                                if qdrant_context:
                                    mcp.set("qdrant_context", qdrant_context)
                                    print(f"üìö Contexto de Qdrant obtenido ({len(qdrant_context)} caracteres)")
                            except Exception as e:
                                print(f"‚ö†Ô∏è Error obteniendo contexto de Qdrant: {e}")
                        
                        # Inyectar el reporte detallado en el contexto compartido
                        try:
                            if isinstance(reporte_txt, str) and len(reporte_txt.strip()) > 0:
                                mcp.set("reporte_detallado", reporte_txt)
                        except Exception:
                            pass
                        try:
                            reply = advisor.call(message)
                        except Exception as e:
                            reply = f"Error del asistente: {e}"
                        # Agregar mensajes al historial en formato messages
                        history = history + [
                            {"role": "user", "content": message},
                            {"role": "assistant", "content": reply},
                        ]
                        # Guardar backend y devolver etiqueta
                        try:
                            bk = advisor.llm.backend()
                            mcp.set("llm_backend", bk)
                        except Exception:
                            bk = "(desconocido)"
                        return history, mcp, advisor, reporte_txt, qdrant_retriever, f'<div class="backend-label">Modelo: {bk}</div>'
                    
                    send_btn.click(
                        fn=_chat_respond,
                        inputs=[user_msg, chat, mcp_state, advisor_state, reporte_state, qdrant_state],
                        outputs=[chat, mcp_state, advisor_state, reporte_state, qdrant_state, backend_label]
                    )
                    user_msg.submit(
                        fn=_chat_respond,
                        inputs=[user_msg, chat, mcp_state, advisor_state, reporte_state, qdrant_state],
                        outputs=[chat, mcp_state, advisor_state, reporte_state, qdrant_state, backend_label]
                    )
            
            
        
        # Eventos con progress
        analizar_btn.click(
            fn=analizar_provincia_completo,
            inputs=[provincia_input, incluir_temp, incluir_comp, fecha_inicio_input, fecha_fin_input],
            outputs=[reporte_output, plot_historico, plot_prediccion, plot_temperatura, plot_comparativo, reporte_state],
            show_progress=True
        )
    
    return app
